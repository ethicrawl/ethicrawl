{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ethicrawl Documentation","text":"<p>Welcome to Ethicrawl, a Python library designed for ethical and respectful web crawling. Ethicrawl provides tools and abstractions to help developers build crawlers that follow best practices, respect site policies, and minimize server impact.</p>"},{"location":"#overview","title":"Overview","text":"<p>Ethicrawl focuses on:</p> <ul> <li>Ethical Crawling: Respectful of robots.txt, rate limits, and server resources</li> <li>Resource Abstractions: Type-safe handling of web resources and collections</li> <li>Policy Enforcement: Automatic compliance with web standards</li> <li>Comprehensive Logging: Detailed visibility into crawler operations</li> <li>Configurability: Fine-grained control over crawler behavior</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install ethicrawl\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code>from ethicrawl import Ethicrawl\nfrom ethicrawl.error import RobotDisallowedError\n\n# Create and bind to a domain\nethicrawl = Ethicrawl()\nethicrawl.bind(\"https://example.com\")\n\n# Get a page - robots.txt rules automatically respected\ntry:\n    response = ethicrawl.get(\"/page.html\")\nexcept RobotDisallowedError:\n    print(\"The site prohibits fetching the page\")\n\n# Release resources when done\nethicrawl.unbind()\n</code></pre>"},{"location":"#examples","title":"Examples","text":"<p>Our examples directory contains practical demonstrations of Ethicrawl's features:</p> <ol> <li>Basic Usage: Simple crawling with automatic robots.txt compliance</li> <li>Domain Whitelisting: Allowing access to secondary domains</li> <li>Chrome Client: Using Chrome browser for JavaScript rendering</li> <li>Sitemap Support: Parsing and using sitemaps</li> <li>Resources and ResourceLists: Working with web resources</li> <li>Proxies and Caching: Using proxy servers</li> <li>Configuration: Configuring Ethicrawl</li> <li>Logging: Using the logging system</li> </ol>"},{"location":"#documentation-guides","title":"Documentation Guides","text":"<ul> <li>Standards: Coding standards and style guide for Ethicrawl development</li> <li>Logging: Detailed guide to Ethicrawl's logging system</li> <li>Documentation: Guidelines for contributing to these docs</li> </ul>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>ethicrawl/\n\u251c\u2500\u2500 core/         # Core abstractions (Resource, Url, etc.)\n\u251c\u2500\u2500 context/      # Context passed around within the system\n\u251c\u2500\u2500 client/       # Client implementations\n\u251c\u2500\u2500 config/       # Configuration system\n\u251c\u2500\u2500 robots/       # Robots.txt parser and enforcer\n\u251c\u2500\u2500 sitemaps/     # Sitemap parser\n\u2514\u2500\u2500 logger/       # Logging system\n</code></pre>"},{"location":"documentation/","title":"Documentation","text":"<p>We follow Google-style docstrings for all code documentation.</p>"},{"location":"documentation/#documentation-focus-areas","title":"Documentation Focus Areas","text":"<ul> <li>All public APIs (methods, classes, and modules) must have comprehensive docstrings</li> <li>Private methods with complex logic should have docstrings</li> <li>Simple private methods or properties may omit docstrings</li> <li>Focus on documentation that enhances IDE tooltips and developer experience</li> </ul>"},{"location":"documentation/#docstring-format","title":"Docstring Format","text":""},{"location":"documentation/#module-docstrings","title":"Module Docstrings","text":"<pre><code>\"\"\"Module for handling robots.txt parsing and permission checking.\n\nThis module provides functionality for fetching, parsing and checking\npermissions against robots.txt files according to the Robots Exclusion\nProtocol.\n\"\"\"\n</code></pre>"},{"location":"documentation/#class-docstrings","title":"Class Docstrings","text":"<pre><code>class Robot:\n    \"\"\"Representation of a robots.txt file with permission checking.\n\n    This class handles fetching and parsing robots.txt files and provides\n    methods to check if URLs can be accessed according to the rules.\n\n    Attributes:\n        url: The URL of the robots.txt file\n        sitemaps: List of sitemap URLs found in robots.txt\n    \"\"\"\n</code></pre>"},{"location":"documentation/#methodfunction-docstrings","title":"Method/Function Docstrings","text":"<pre><code>def can_fetch(self, url: str, user_agent: str = None) -&gt; bool:\n    \"\"\"Check if a URL can be fetched according to robots.txt rules.\n\n    Args:\n        url: The URL to check against robots.txt rules\n        user_agent: Optional user agent string to use for checking.\n            Defaults to the client's configured user agent.\n\n    Returns:\n        True if the URL is allowed, False otherwise.\n\n    Raises:\n        RobotDisallowedError: If access is denied and raise_on_disallow=True\n        ValueError: If the URL is malformed\n\n    Example:\n        &gt;&gt;&gt; robot = Robot(\"https://example.com/robots.txt\")\n        &gt;&gt;&gt; robot.can_fetch(\"https://example.com/allowed\")\n        True\n        &gt;&gt;&gt; robot.can_fetch(\"https://example.com/disallowed\")\n        False\n</code></pre>"},{"location":"documentation/#property-docstrings","title":"Property Docstrings","text":"<pre><code>@property\ndef sitemaps(self) -&gt; List[str]:\n    \"\"\"List of sitemap URLs found in robots.txt.\n\n    Returns:\n        List of sitemap URLs as strings.\n    \"\"\"\n</code></pre>"},{"location":"documentation/#constructor-docstrings","title":"Constructor Docstrings","text":"<pre><code>def __init__(self, url: str, context: Context = None):\n    \"\"\"Initialize a Robot instance.\n\n    Args:\n        url: URL to the robots.txt file\n        context: Optional context for the request.\n            If not provided, a default context will be created.\n    \"\"\"\n</code></pre>"},{"location":"documentation/#coverage-requirements","title":"Coverage Requirements","text":"<ul> <li>All public methods, classes, and modules must have docstrings (100% coverage)</li> <li>Private methods with complex logic should have docstrings</li> <li>Simple private methods or properties may omit docstrings</li> <li>The overall project requires a minimum of 95% docstring coverage as measured by interrogate</li> </ul>"},{"location":"documentation/#special-cases","title":"Special Cases","text":""},{"location":"documentation/#private-methods","title":"Private Methods","text":"<p>Private methods (starting with underscore) should have docstrings if they: - Contain complex logic - Are called from multiple places - Would benefit from documentation for maintainers</p>"},{"location":"documentation/#one-line-docstrings","title":"One-line Docstrings","text":"<p>For simple methods with obvious behavior, a one-line docstring is acceptable:</p> <pre><code>def is_allowed(self, url: str) -&gt; bool:\n    \"\"\"Return True if the URL is allowed by robots.txt.\"\"\"\n</code></pre>"},{"location":"documentation/#verification-approach","title":"Verification Approach","text":"<p>Documentation quality is verified through code review rather than automated metrics. Reviewers should confirm that:</p> <ul> <li>Public APIs have clear, complete docstrings</li> <li>Examples are provided for non-obvious usage</li> <li>Type information is present in docstrings</li> <li>Error cases and exceptions are documented</li> </ul>"},{"location":"documentation/#documentation-language-guidelines","title":"Documentation Language Guidelines","text":"<p>When writing documentation, follow these language principles:</p> <ol> <li>Be objective - Avoid subjective descriptors like \"elegant\", \"beautiful\", or \"clever\"</li> <li>Be precise - Focus on what code does, not subjective quality judgments</li> <li>Be technical - Use concrete technical terms rather than metaphorical language</li> <li>Be consistent - Maintain a neutral, professional tone throughout documentation</li> </ol>"},{"location":"documentation/#examples","title":"Examples:","text":"<p>Avoid: <pre><code>\"\"\"This elegant pattern enables seamless chaining of operations.\"\"\"\n</code></pre></p> <p>Better: <pre><code>\"\"\"This design allows operation outputs to serve as inputs to other operations.\"\"\"\n</code></pre></p> <p>Avoid <pre><code>\"\"\"Beautiful integration between components creates a powerful system.\"\"\"\n</code></pre></p> <p>Better <code>Components communicate through well-defined interfaces that enable extensibility.</code></p>"},{"location":"logging/","title":"Logging Standards","text":""},{"location":"logging/#logging-standards-for-ethicrawl","title":"Logging Standards for Ethicrawl","text":"<p>Good logging practices are essential for troubleshooting, monitoring, and understanding application behavior. This document outlines our logging standards for the Ethicrawl codebase.</p>"},{"location":"logging/#log-levels-and-their-uses","title":"Log Levels and Their Uses","text":""},{"location":"logging/#critical-loggingcritical-50","title":"CRITICAL (logging.CRITICAL, 50)","text":"<p>Use for severe errors that prevent core functionality from working.</p>"},{"location":"logging/#when-to-use","title":"When to use:","text":"<ul> <li>Application cannot continue functioning</li> <li>Data corruption or loss has occurred</li> <li>Security breaches or compromises</li> <li>Resource exhaustion that threatens system stability</li> </ul>"},{"location":"logging/#examples","title":"Examples:","text":"<pre><code>logger.critical(f\"Failed to initialize client: {error}\")\nlogger.critical(f\"Persistent storage corruption detected in {file_path}\")\n</code></pre>"},{"location":"logging/#error-loggingerror-40","title":"ERROR (logging.ERROR, 40)","text":"<p>Use for runtime errors that prevent specific operations from completing but don't crash the application.</p>"},{"location":"logging/#when-to-use_1","title":"When to use:","text":"<ul> <li>Failed HTTP requests</li> <li>Failed data processing operations</li> <li>Configuration errors</li> <li>External service unavailability</li> <li>Unexpected exceptions in non-critical paths</li> </ul>"},{"location":"logging/#examples_1","title":"Examples:","text":"<pre><code>logger.error(f\"HTTP request failed: {status_code} {reason}\")\nlogger.error(f\"Failed to parse sitemap at {url}: {error_message}\")\n</code></pre>"},{"location":"logging/#warning-loggingwarning-30","title":"WARNING (logging.WARNING, 30)","text":"<p>Use for conditions that might cause problems but allow operations to continue.</p>"},{"location":"logging/#when-to-use_2","title":"When to use:","text":"<ul> <li>Deprecated feature usage</li> <li>Slow response times</li> <li>Retrying operations after recoverable failures</li> <li>Access denied for certain operations</li> <li>Unexpected data formats that can be handled</li> <li>Rate limiting being applied</li> </ul>"},{"location":"logging/#examples_2","title":"Examples:","text":"<pre><code>logger.warning(f\"URL disallowed by robots.txt: {url}\")\nlogger.warning(f\"Slow response from {domain}: {response_time}s\")\nlogger.warning(f\"Retrying request ({retry_count}/{max_retries})\")\n</code></pre>"},{"location":"logging/#info-logginginfo-20","title":"INFO (logging.INFO, 20)","text":"<p>Use for normal operational events and milestones.</p>"},{"location":"logging/#when-to-use_3","title":"When to use:","text":"<ul> <li>Application startup and shutdown</li> <li>Configuration settings</li> <li>Successful site binding and crawling</li> <li>Processing milestones</li> <li>Summary information about operations</li> <li>Changes to application state</li> </ul>"},{"location":"logging/#examples_3","title":"Examples:","text":"<pre><code>logger.info(f\"Bound to site: {url}\")\nlogger.info(f\"Robots.txt processed: {allowed_count} allowed paths, {disallowed_count} disallowed\")\nlogger.info(f\"Processed {page_count} pages in {duration}s\")\n</code></pre>"},{"location":"logging/#debug-loggingdebug-10","title":"DEBUG (logging.DEBUG, 10)","text":"<p>Use for detailed information useful during development and debugging.</p>"},{"location":"logging/#when-to-use_4","title":"When to use:","text":"<ul> <li>Function entry/exit points</li> <li>Variable values and state changes</li> <li>Decision logic paths</li> <li>Low-level HTTP details</li> <li>Parsing steps</li> <li>Rate limiting details</li> </ul>"},{"location":"logging/#examples_4","title":"Examples:","text":"<pre><code>logger.debug(f\"Processing URL: {url}\")\nlogger.debug(f\"Page found in cache, age: {cache_age}s\")\nlogger.debug(f\"Parser state: {current_state}\")\n</code></pre>"},{"location":"logging/#logging-best-practices","title":"Logging Best Practices","text":"<ol> <li>Be Concise and Specific</li> <li>Include exactly what happened and where</li> <li> <p>Use active voice (e.g., \"Failed to connect\" instead of \"Connection failure occurred\")</p> </li> <li> <p>Include Context</p> </li> <li>Always include relevant identifiers (URLs, IDs, component names)</li> <li>Include relevant variable values</li> <li> <p>For errors, include exception messages and/or stack traces</p> </li> <li> <p>Be Consistent</p> </li> <li>Use consistent terminology across similar log messages</li> <li>Use consistent formatting for similar events</li> <li> <p>Use sentence case for log messages (capitalize first word)</p> </li> <li> <p>Avoid Sensitive Information</p> </li> <li>No authentication credentials</li> <li>No personal data</li> <li> <p>No sensitive headers or tokens</p> </li> <li> <p>Use Structured Fields for Machine Parsing</p> </li> <li>Place structured data at the end of the message</li> <li>Use consistent key-value format: <code>key=value</code></li> </ol>"},{"location":"logging/#component-specific-guidelines","title":"Component-Specific Guidelines","text":"<p>Each component should have a consistent logging identity:</p> <ol> <li>Robot/Robots.txt</li> <li>INFO: Robots.txt fetching and parsing results</li> <li>WARNING: Disallowed access attempts</li> <li> <p>ERROR: Failed to fetch/parse robots.txt</p> </li> <li> <p>HTTP Client</p> </li> <li>DEBUG: Request details</li> <li>INFO: Rate limiting information</li> <li>WARNING: Retries and slow responses</li> <li> <p>ERROR: Failed requests</p> </li> <li> <p>Sitemap</p> </li> <li>INFO: Sitemap discovery and parsing</li> <li>WARNING: Malformed but recoverable sitemap content</li> <li>ERROR: Failed sitemap fetching/parsing</li> </ol> <p>By following these guidelines, we'll maintain a consistent and helpful logging strategy across the Ethicrawl codebase.</p>"},{"location":"standards/","title":"Coding Standards","text":""},{"location":"standards/#python-code-standards","title":"Python Code Standards","text":""},{"location":"standards/#general-requirements","title":"General Requirements","text":"<ul> <li>Python Version: We target Python 3.10 and above</li> <li>Code may work on earlier versions but is not tested or supported</li> <li>Line Endings: Use UNIX-style line endings (LF, <code>\\n</code>)</li> <li>Indentation: Use 4 spaces for indentation (no tabs)</li> <li>Maximum Line Length: 88 characters (Black default)</li> </ul>"},{"location":"standards/#code-formatting","title":"Code Formatting","text":"<p>We use Black as our code formatter with default settings:</p> <pre><code># Install Black\npip install black\n\n# Format a single file\nblack path/to/file.py\n\n# Format all Python files in a directory\nblack directory_name/\n</code></pre>"},{"location":"standards/#import-organization","title":"Import Organization","text":"<p>Imports should be grouped in the following order, with a blank line between each group:</p> <ul> <li>Standard library imports</li> <li>Third-party imports</li> <li>Local application imports</li> </ul> <pre><code># Standard library\nimport os\nfrom datetime import datetime\n\n# Third-party\nimport requests\nfrom bs4 import BeautifulSoup\n\n# Local\nfrom ethicrawl.core import Resource\nfrom ethicrawl.config import Config\n</code></pre>"},{"location":"standards/#type-hints","title":"Type Hints","text":"<p>Use type hints for all public methods and functions:</p> <pre><code>def process_url(url: str, timeout: Optional[int] = None) -&gt; Dict[str, Any]:\n    \"\"\"Process the given URL and return results.\"\"\"\n</code></pre>"},{"location":"standards/#methodfunction-docstrings","title":"Method/Function Docstrings","text":"<pre><code>def can_fetch(self, url: str, user_agent: str = None) -&gt; bool:\n    \"\"\"Check if a URL can be fetched according to robots.txt rules.\n\n    Args:\n        url: The URL to check against robots.txt rules\n        user_agent: Optional user agent string to use for checking.\n            Defaults to the client's configured user agent.\n\n    Returns:\n        True if the URL is allowed, False otherwise.\n\n    Raises:\n        RobotDisallowedError: If access is denied and raise_on_disallow=True\n        ValueError: If the URL is malformed\n    \"\"\"\n</code></pre>"},{"location":"standards/#error-handling-style-guide-for-ethicrawl","title":"Error Handling Style Guide for Ethicrawl","text":"<p>A consistent approach to error handling improves code readability and helps developers understand and handle errors effectively. This document outlines our standards for raising exceptions in the Ethicrawl codebase.</p>"},{"location":"standards/#general-principles","title":"General Principles","text":"<ol> <li>Be specific - Use the most specific exception type appropriate for the error</li> <li>Be descriptive - Error messages should help users identify and fix problems</li> <li>Be consistent - Follow the same patterns throughout the codebase</li> </ol>"},{"location":"standards/#standard-exception-types","title":"Standard Exception Types","text":""},{"location":"standards/#typeerror","title":"TypeError","text":"<p>Use for incorrect argument types or invalid operations on types.</p>"},{"location":"standards/#format","title":"Format:","text":"<pre><code>raise TypeError(f\"Expected {expected_type}, got {type(actual).__name__}\")\n</code></pre>"},{"location":"standards/#examples","title":"Examples:","text":"<pre><code>raise TypeError(f\"Expected string, Url, or Resource, got {type(resource).__name__}\")\nraise TypeError(\"headers must be a Headers instance or dictionary\")\n</code></pre>"},{"location":"standards/#valueerror","title":"ValueError","text":"<p>Use for arguments that have the right type but an invalid value.</p>"},{"location":"standards/#format_1","title":"Format:","text":"<pre><code>raise ValueError(f\"{parameter_name} must be {constraint}\")\n</code></pre>"},{"location":"standards/#examples_1","title":"Examples:","text":"<pre><code>raise ValueError(\"jitter must be between 0.0 and 1.0\")\nraise ValueError(\"max_retries cannot be negative\")\n</code></pre>"},{"location":"standards/#domain-specific-exceptions","title":"Domain-Specific Exceptions","text":"<p>Create custom exceptions for domain-specific errors. All custom exceptions should:</p> <ol> <li>Inherit from appropriate base exceptions</li> <li>Include \"Error\" in the class name</li> <li>Be placed in a relevant _error.py module</li> </ol>"},{"location":"standards/#example","title":"Example:","text":"<pre><code>class RobotDisallowedError(ValueError):\n    \"\"\"Raised when access to a URL is disallowed by robots.txt rules.\"\"\"\n</code></pre>"},{"location":"standards/#error-message-guidelines","title":"Error Message Guidelines","text":"<ol> <li>Be specific about what went wrong</li> <li>Provide the invalid value when helpful</li> <li>Suggest a fix when possible</li> <li>Use consistent terminology across similar errors</li> </ol>"},{"location":"standards/#documenting-exceptions","title":"Documenting Exceptions","text":"<pre><code>def function_name():\n    \"\"\"Function description.\n\n    Args:\n        param_name: Parameter description.\n\n    Returns:\n        Return description.\n\n    Raises:\n        ExceptionType: Condition when raised.\n        AnotherException: Another condition.\n    \"\"\"\n</code></pre> <p>Always document exceptions in docstrings:</p>"},{"location":"standards/#error-assertions","title":"Error Assertions","text":"<p>For internal logic verification, use assertions with descriptive messages:</p> <pre><code>assert isinstance(item, Resource), f\"Expected Resource, got {type(item).__name__}\"\n</code></pre> <p>By following these guidelines, we'll maintain a consistent approach to error handling across the Ethicrawl codebase.</p>"}]}