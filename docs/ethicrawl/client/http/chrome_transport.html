<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>ethicrawl.client.http.chrome_transport API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ethicrawl.client.http.chrome_transport</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ethicrawl.client.http.chrome_transport.ChromeTransport"><code class="flex name class">
<span>class <span class="ident">ChromeTransport</span></span>
<span>(</span><span>context:Â <a title="ethicrawl.context.context.Context" href="../../context/context.html#ethicrawl.context.context.Context">Context</a>,<br>headless=True,<br>wait_time=3)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ChromeTransport(Transport):
    &#34;&#34;&#34;Selenium-based transport implementation using Chrome/Chromium.

    This transport provides browser automation capabilities for fetching
    JavaScript-rendered content and interacting with dynamic websites. It
    uses Selenium WebDriver to control Chrome, extract network information,
    and process the rendered DOM.

    Features:
    - Full JavaScript execution and rendering
    - Network traffic inspection via Chrome DevTools Protocol
    - Automatic XML content extraction from browser rendering
    - Proxy configuration support
    - Configurable wait time for dynamic content

    Attributes:
        driver: Selenium WebDriver instance controlling Chrome
        _wait_time: Time to wait for dynamic content to load (seconds)
        _user_agent: Browser&#39;s actual user agent string

    Example:
        &gt;&gt;&gt; from ethicrawl.context import Context
        &gt;&gt;&gt; from ethicrawl.client.http import ChromeTransport, HttpRequest
        &gt;&gt;&gt; from ethicrawl.core import Resource
        &gt;&gt;&gt; context = Context(Resource(&#34;https://example.com&#34;))
        &gt;&gt;&gt; transport = ChromeTransport(context, headless=True)
        &gt;&gt;&gt; request = HttpRequest(Resource(&#34;https://spa-example.com&#34;))
        &gt;&gt;&gt; response = transport.get(request)
        &gt;&gt;&gt; &#34;dynamically loaded content&#34; in response.text
        True
    &#34;&#34;&#34;

    def __init__(self, context: Context, headless=True, wait_time=3):
        &#34;&#34;&#34;Initialize the Chrome transport with browser configuration.

        Sets up a Chrome browser instance with appropriate options for
        web scraping, including performance logging for network inspection.

        Args:
            context: The context to use for logging and resource resolution
            headless: Whether to run Chrome in headless mode (no GUI)
            wait_time: Time to wait for dynamic content after page load (seconds)

        Note:
            Chrome/Chromium must be installed on the system for this to work
        &#34;&#34;&#34;
        self._context = context
        self._logger = self._context.logger(&#34;client.chrome&#34;)
        self._wait_time = wait_time
        self._user_agent = None  # Will be populated after first request

        # Set up Chrome options
        options = Options()
        if headless:
            options.add_argument(&#34;--headless&#34;)

        options.add_argument(&#34;--no-sandbox&#34;)
        options.add_argument(&#34;--disable-dev-shm-usage&#34;)
        options.add_argument(&#34;--disable-gpu&#34;)
        options.add_argument(&#34;--window-size=1920,1080&#34;)

        # Set up proxy if configured
        http_proxy = Config().http.proxies.http
        https_proxy = Config().http.proxies.https

        if http_proxy or https_proxy:
            # If both HTTP and HTTPS use the same proxy (common case)
            if http_proxy and https_proxy and str(http_proxy) == str(https_proxy):
                options.add_argument(f&#34;--proxy-server={http_proxy}&#34;)
            else:
                # Handle case when HTTP and HTTPS proxies are different
                if http_proxy:
                    options.add_argument(f&#34;--proxy-server=http={http_proxy}&#34;)
                if https_proxy:
                    options.add_argument(f&#34;--proxy-server=https={https_proxy}&#34;)

        # Enable performance logging - critical for getting network details
        options.set_capability(
            &#34;goog:loggingPrefs&#34;, {&#34;performance&#34;: &#34;ALL&#34;, &#34;browser&#34;: &#34;ALL&#34;}
        )

        # Initialize the driver
        self.driver = webdriver.Chrome(options=options)

    @property
    def user_agent(self) -&gt; str:
        &#34;&#34;&#34;Get the actual Chrome user agent string.

        Returns the browser&#39;s native User-Agent rather than a configured one
        to maintain browser fingerprint authenticity.

        Returns:
            The actual Chrome user agent string
        &#34;&#34;&#34;
        # If we already know the UA, return it
        if self._user_agent:
            return self._user_agent

        # If we haven&#39;t made a request yet, get it from the browser
        try:
            # Navigate to a simple page to avoid external requests
            self.driver.get(&#34;about:blank&#34;)
            # Execute JavaScript to get the user agent
            self._user_agent = self.driver.execute_script(&#34;return navigator.userAgent;&#34;)
            return str(self._user_agent)
        except Exception as e:
            # Return a default value if we can&#39;t determine it yet
            return &#34;Mozilla/5.0 (Unknown) Chrome/Unknown Safari/Unknown&#34;

    @user_agent.setter
    def user_agent(self, agent: str):
        &#34;&#34;&#34;Record requested user agent (not actually applied).

        For Chrome, we don&#39;t modify the browser&#39;s actual User-Agent to
        maintain browser authenticity and avoid detection. This method
        logs that a change was requested but doesn&#39;t apply it.

        Args:
            agent: Requested user agent string
        &#34;&#34;&#34;
        # For Chrome, we just record that this was requested but don&#39;t modify
        # the browser&#39;s actual User-Agent to maintain authenticity
        self._logger.debug(
            &#34;Note: User-Agent override requested to %s but Chrome uses browser&#39;s native User-Agent&#34;,
            agent,
        )

    def get(self, request: HttpRequest) -&gt; HttpResponse:
        &#34;&#34;&#34;Fetch a page using Chrome/Selenium with full JavaScript rendering.

        Navigates to the URL, waits for content to load, and extracts the
        rendered DOM along with network traffic information. Handles special
        cases like XML content that may be rendered differently in a browser.

        Args:
            request: The HttpRequest object containing URL, headers, etc.

        Returns:
            HttpResponse object with rendered content, actual status code,
            and response headers extracted from network logs

        Raises:
            IOError: If the navigation or page processing fails

        Note:
            Headers provided in the request are logged but may not be fully
            applied due to limitations in Selenium&#39;s header control
        &#34;&#34;&#34;
        url = &#34;unknown&#34;

        try:

            # Extract parameters from request object
            url = str(request.url)
            timeout = request.timeout

            # Clear logs before request
            if self.driver.get_log(&#34;performance&#34;):
                pass  # Just accessing to clear buffer

            # Set page load timeout
            self.driver.set_page_load_timeout(timeout)

            # Navigate to URL
            self.driver.get(url)

            # Note: While we can&#39;t directly set most headers in Selenium,
            # we can record that headers were requested
            if request.headers:
                # Just log that headers were requested but can&#39;t be fully applied
                header_names = &#34;, &#34;.join(request.headers.keys())
                self._logger.debug(
                    &#34;Note: Headers requested (%s) but Chrome has limited header support&#34;,
                    header_names,
                )

            # Update user agent information
            self._user_agent = self.driver.execute_script(&#34;return navigator.userAgent;&#34;)

            # Wait for page to load
            try:
                WebDriverWait(self.driver, timeout or Config().http.timeout).until(
                    EC.presence_of_element_located((By.TAG_NAME, &#34;body&#34;))
                )
            except Exception as exc:  # pragma: no cover
                self._logger.warning(
                    &#34;Page load wait timed out (continuing anyway): %s&#34;, exc
                )

            # Additional wait for dynamic content if specified
            if self._wait_time:
                sleep(self._wait_time)

            # Get page source and final URL
            page_source = self.driver.page_source
            final_url = self.driver.current_url

            # Extract network information from performance logs
            status_code, response_headers, mime_type = self._get_response_information(
                url, final_url
            )

            # Convert page source to bytes for content
            content_bytes = page_source.encode(&#34;utf-8&#34;)

            # Handle XML content if needed
            if mime_type and (&#34;xml&#34; in mime_type or url.lower().endswith(&#34;.xml&#34;)):
                # Process XML content when rendered as HTML
                content_bytes = self._extract_xml_content(page_source)

            # Create response headers
            headers = {
                &#34;URL&#34;: final_url,
                &#34;Content-Type&#34;: mime_type or &#34;text/html&#34;,
                **response_headers,
            }

            # Create the response with text properly decoded from content
            response = HttpResponse(
                url=Url(final_url) or request.url,
                request=request,
                status_code=status_code or 200,
                text=content_bytes.decode(&#34;utf-8&#34;, errors=&#34;replace&#34;),
                headers=Headers(headers),
                content=content_bytes,
            )

            return response

        except Exception as e:  # pragma: no cover
            raise IOError(f&#34;Error fetching {url} with Chrome: {e}&#34;)

    def _extract_xml_content(self, content_str: str) -&gt; bytes:

        try:
            # Check if this is a browser-rendered XML page
            if &#39;&lt;div id=&#34;webkit-xml-viewer-source-xml&#34;&gt;&#39; in content_str:
                # Parse HTML
                parser = etree.HTMLParser(huge_tree=False)
                root = html.fromstring(content_str, parser=parser)

                # Extract content from the XML viewer div
                xml_div = root.xpath(
                    &#39;//div[@id=&#34;webkit-xml-viewer-source-xml&#34;]&#39;,
                )

                if isinstance(xml_div, list) and xml_div:
                    first_div = xml_div[0]

                    xml_content = &#34;&#34;.join(
                        etree.tostring(child, encoding=&#34;unicode&#34;)  # type: ignore
                        for child in list(first_div)
                    )
                    return xml_content.encode(&#34;utf-8&#34;)

        except Exception as exc:  # pragma: no cover
            self._logger.warning(
                &#34;Failed to extract XML from browser response: %s&#34;,
                exc,
            )

        # Return original content encoded as bytes if extraction failed
        return content_str.encode(&#34;utf-8&#34;)

    def _extract_response_info_from_log_entry(
        self, entry: dict[str, Any]
    ) -&gt; tuple[dict[str, Any], dict[str, Any]] | None:

        try:
            log_data = loads(entry[&#34;message&#34;])[&#34;message&#34;]
            if log_data[&#34;method&#34;] != &#34;Network.responseReceived&#34;:
                return None

            params = log_data.get(&#34;params&#34;, {})
            response = params.get(&#34;response&#34;, {})
            return params, response
        except Exception as exc:
            self._logger.debug(
                &#34;Error processing log entry: %s&#34;,
                exc,
            )
            return None

    def _extract_response_info_from_response(
        self, response: dict[str, Any]
    ) -&gt; tuple[int | None, dict[str, str], str | None]:
        try:
            status_code = response.get(&#34;status&#34;)
            mime_type = response.get(&#34;mimeType&#34;)

            # Extract headers
            headers = {}
            for key, value in response.get(&#34;headers&#34;, {}).items():
                headers[key] = value
            return status_code, headers, mime_type
        except Exception as exc:
            self._logger.debug(&#34;Error processing log entry: %s&#34;, exc)
            return None, {}, None  # Return 3-tuple with default values

    def _get_response_information(
        self, requested_url: str, final_url: str
    ) -&gt; tuple[int | None, dict[str, str], str | None]:
        # Default values if we can&#39;t find anything
        default_status = 200  # Most browsers show content even without status
        default_headers: dict[str, str] = {}
        default_mime = &#34;text/html&#34;  # Assume HTML if not specified
        try:
            logs = self.driver.get_log(&#34;performance&#34;)
            document_response = None
            for entry in logs:
                result = self._extract_response_info_from_log_entry(entry)
                if not result:
                    # Skip non-response entries
                    continue

                params, response = result
                url = response.get(&#34;url&#34;, &#34;&#34;)

                # First priority: exact URL match
                if url in (requested_url, final_url):
                    return self._extract_response_info_from_response(response)

                # Second priority: document response (save for fallback)
                if params.get(&#34;type&#34;) == &#34;Document&#34; and not document_response:
                    document_response = response

            # If we found a document response, use it as fallback
            if document_response:
                return self._extract_response_info_from_response(document_response)

            # Default fallback if no matching response found
            return default_status, default_headers, default_mime

        except Exception as exc:  # pragma: no cover
            self._logger.warning(&#34;Error extracting network info: %s&#34;, exc)
            return default_status, default_headers, default_mime

    def __del__(self):
        &#34;&#34;&#34;Close browser when transport is garbage collected.

        Ensures proper cleanup of Chrome processes when the transport
        is no longer needed to avoid leaving orphaned browser instances.
        &#34;&#34;&#34;
        try:
            if hasattr(self, &#34;driver&#34;) and self.driver:
                self.driver.quit()
        except Exception as exc:  # pragma: no cover
            # Use the logger if it exists, otherwise we can&#39;t log during cleanup
            if hasattr(self, &#34;_logger&#34;):
                self._logger.debug(&#34;Error closing browser during cleanup: %s&#34;, exc)
            else:
                raise exc</code></pre>
</details>
<div class="desc"><p>Selenium-based transport implementation using Chrome/Chromium.</p>
<p>This transport provides browser automation capabilities for fetching
JavaScript-rendered content and interacting with dynamic websites. It
uses Selenium WebDriver to control Chrome, extract network information,
and process the rendered DOM.</p>
<p>Features:
- Full JavaScript execution and rendering
- Network traffic inspection via Chrome DevTools Protocol
- Automatic XML content extraction from browser rendering
- Proxy configuration support
- Configurable wait time for dynamic content</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>driver</code></strong></dt>
<dd>Selenium WebDriver instance controlling Chrome</dd>
<dt><strong><code>_wait_time</code></strong></dt>
<dd>Time to wait for dynamic content to load (seconds)</dd>
<dt><strong><code>_user_agent</code></strong></dt>
<dd>Browser's actual user agent string</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from ethicrawl.context import Context
&gt;&gt;&gt; from ethicrawl.client.http import ChromeTransport, HttpRequest
&gt;&gt;&gt; from ethicrawl.core import Resource
&gt;&gt;&gt; context = Context(Resource(&quot;https://example.com&quot;))
&gt;&gt;&gt; transport = ChromeTransport(context, headless=True)
&gt;&gt;&gt; request = HttpRequest(Resource(&quot;https://spa-example.com&quot;))
&gt;&gt;&gt; response = transport.get(request)
&gt;&gt;&gt; &quot;dynamically loaded content&quot; in response.text
True
</code></pre>
<p>Initialize the Chrome transport with browser configuration.</p>
<p>Sets up a Chrome browser instance with appropriate options for
web scraping, including performance logging for network inspection.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>context</code></strong></dt>
<dd>The context to use for logging and resource resolution</dd>
<dt><strong><code>headless</code></strong></dt>
<dd>Whether to run Chrome in headless mode (no GUI)</dd>
<dt><strong><code>wait_time</code></strong></dt>
<dd>Time to wait for dynamic content after page load (seconds)</dd>
</dl>
<h2 id="note">Note</h2>
<p>Chrome/Chromium must be installed on the system for this to work</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="ethicrawl.client.transport.Transport" href="../transport.html#ethicrawl.client.transport.Transport">Transport</a></li>
<li>abc.ABC</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="ethicrawl.client.http.chrome_transport.ChromeTransport.user_agent"><code class="name">prop <span class="ident">user_agent</span> :Â str</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def user_agent(self) -&gt; str:
    &#34;&#34;&#34;Get the actual Chrome user agent string.

    Returns the browser&#39;s native User-Agent rather than a configured one
    to maintain browser fingerprint authenticity.

    Returns:
        The actual Chrome user agent string
    &#34;&#34;&#34;
    # If we already know the UA, return it
    if self._user_agent:
        return self._user_agent

    # If we haven&#39;t made a request yet, get it from the browser
    try:
        # Navigate to a simple page to avoid external requests
        self.driver.get(&#34;about:blank&#34;)
        # Execute JavaScript to get the user agent
        self._user_agent = self.driver.execute_script(&#34;return navigator.userAgent;&#34;)
        return str(self._user_agent)
    except Exception as e:
        # Return a default value if we can&#39;t determine it yet
        return &#34;Mozilla/5.0 (Unknown) Chrome/Unknown Safari/Unknown&#34;</code></pre>
</details>
<div class="desc"><p>Get the actual Chrome user agent string.</p>
<p>Returns the browser's native User-Agent rather than a configured one
to maintain browser fingerprint authenticity.</p>
<h2 id="returns">Returns</h2>
<p>The actual Chrome user agent string</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="ethicrawl.client.http.chrome_transport.ChromeTransport.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self,<br>request:Â <a title="ethicrawl.client.http.http_request.HttpRequest" href="http_request.html#ethicrawl.client.http.http_request.HttpRequest">HttpRequest</a>) â>Â <a title="ethicrawl.client.http.http_response.HttpResponse" href="http_response.html#ethicrawl.client.http.http_response.HttpResponse">HttpResponse</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self, request: HttpRequest) -&gt; HttpResponse:
    &#34;&#34;&#34;Fetch a page using Chrome/Selenium with full JavaScript rendering.

    Navigates to the URL, waits for content to load, and extracts the
    rendered DOM along with network traffic information. Handles special
    cases like XML content that may be rendered differently in a browser.

    Args:
        request: The HttpRequest object containing URL, headers, etc.

    Returns:
        HttpResponse object with rendered content, actual status code,
        and response headers extracted from network logs

    Raises:
        IOError: If the navigation or page processing fails

    Note:
        Headers provided in the request are logged but may not be fully
        applied due to limitations in Selenium&#39;s header control
    &#34;&#34;&#34;
    url = &#34;unknown&#34;

    try:

        # Extract parameters from request object
        url = str(request.url)
        timeout = request.timeout

        # Clear logs before request
        if self.driver.get_log(&#34;performance&#34;):
            pass  # Just accessing to clear buffer

        # Set page load timeout
        self.driver.set_page_load_timeout(timeout)

        # Navigate to URL
        self.driver.get(url)

        # Note: While we can&#39;t directly set most headers in Selenium,
        # we can record that headers were requested
        if request.headers:
            # Just log that headers were requested but can&#39;t be fully applied
            header_names = &#34;, &#34;.join(request.headers.keys())
            self._logger.debug(
                &#34;Note: Headers requested (%s) but Chrome has limited header support&#34;,
                header_names,
            )

        # Update user agent information
        self._user_agent = self.driver.execute_script(&#34;return navigator.userAgent;&#34;)

        # Wait for page to load
        try:
            WebDriverWait(self.driver, timeout or Config().http.timeout).until(
                EC.presence_of_element_located((By.TAG_NAME, &#34;body&#34;))
            )
        except Exception as exc:  # pragma: no cover
            self._logger.warning(
                &#34;Page load wait timed out (continuing anyway): %s&#34;, exc
            )

        # Additional wait for dynamic content if specified
        if self._wait_time:
            sleep(self._wait_time)

        # Get page source and final URL
        page_source = self.driver.page_source
        final_url = self.driver.current_url

        # Extract network information from performance logs
        status_code, response_headers, mime_type = self._get_response_information(
            url, final_url
        )

        # Convert page source to bytes for content
        content_bytes = page_source.encode(&#34;utf-8&#34;)

        # Handle XML content if needed
        if mime_type and (&#34;xml&#34; in mime_type or url.lower().endswith(&#34;.xml&#34;)):
            # Process XML content when rendered as HTML
            content_bytes = self._extract_xml_content(page_source)

        # Create response headers
        headers = {
            &#34;URL&#34;: final_url,
            &#34;Content-Type&#34;: mime_type or &#34;text/html&#34;,
            **response_headers,
        }

        # Create the response with text properly decoded from content
        response = HttpResponse(
            url=Url(final_url) or request.url,
            request=request,
            status_code=status_code or 200,
            text=content_bytes.decode(&#34;utf-8&#34;, errors=&#34;replace&#34;),
            headers=Headers(headers),
            content=content_bytes,
        )

        return response

    except Exception as e:  # pragma: no cover
        raise IOError(f&#34;Error fetching {url} with Chrome: {e}&#34;)</code></pre>
</details>
<div class="desc"><p>Fetch a page using Chrome/Selenium with full JavaScript rendering.</p>
<p>Navigates to the URL, waits for content to load, and extracts the
rendered DOM along with network traffic information. Handles special
cases like XML content that may be rendered differently in a browser.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong></dt>
<dd>The HttpRequest object containing URL, headers, etc.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>HttpResponse object with rendered content, actual status code,
and response headers extracted from network logs</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>IOError</code></dt>
<dd>If the navigation or page processing fails</dd>
</dl>
<h2 id="note">Note</h2>
<p>Headers provided in the request are logged but may not be fully
applied due to limitations in Selenium's header control</p></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="ethicrawl.client.transport.Transport" href="../transport.html#ethicrawl.client.transport.Transport">Transport</a></b></code>:
<ul class="hlist">
<li><code><a title="ethicrawl.client.transport.Transport.head" href="../transport.html#ethicrawl.client.transport.Transport.head">head</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ethicrawl.client.http" href="index.html">ethicrawl.client.http</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ethicrawl.client.http.chrome_transport.ChromeTransport" href="#ethicrawl.client.http.chrome_transport.ChromeTransport">ChromeTransport</a></code></h4>
<ul class="">
<li><code><a title="ethicrawl.client.http.chrome_transport.ChromeTransport.get" href="#ethicrawl.client.http.chrome_transport.ChromeTransport.get">get</a></code></li>
<li><code><a title="ethicrawl.client.http.chrome_transport.ChromeTransport.user_agent" href="#ethicrawl.client.http.chrome_transport.ChromeTransport.user_agent">user_agent</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
